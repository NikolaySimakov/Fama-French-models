{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from lightgbm import plot_importance, LGBMRegressor\n",
    "import getFamaFrenchFactors as gff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Symbol</th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>...</th>\n",
       "      <th>WTW</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>20.122227</td>\n",
       "      <td>4.496877</td>\n",
       "      <td>6.470741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.952162</td>\n",
       "      <td>7.994444</td>\n",
       "      <td>32.212460</td>\n",
       "      <td>37.090000</td>\n",
       "      <td>23.694084</td>\n",
       "      <td>...</td>\n",
       "      <td>52.883579</td>\n",
       "      <td>9.905468</td>\n",
       "      <td>41.963718</td>\n",
       "      <td>12.918809</td>\n",
       "      <td>43.185623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.158102</td>\n",
       "      <td>52.587051</td>\n",
       "      <td>28.670000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>19.903643</td>\n",
       "      <td>5.005957</td>\n",
       "      <td>6.481929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.799042</td>\n",
       "      <td>7.967778</td>\n",
       "      <td>32.411549</td>\n",
       "      <td>37.700001</td>\n",
       "      <td>23.656675</td>\n",
       "      <td>...</td>\n",
       "      <td>52.765053</td>\n",
       "      <td>10.115747</td>\n",
       "      <td>44.515926</td>\n",
       "      <td>12.765595</td>\n",
       "      <td>43.354244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.092571</td>\n",
       "      <td>54.251759</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>19.832930</td>\n",
       "      <td>4.798554</td>\n",
       "      <td>6.378825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.903446</td>\n",
       "      <td>7.933333</td>\n",
       "      <td>32.756096</td>\n",
       "      <td>37.619999</td>\n",
       "      <td>23.611784</td>\n",
       "      <td>...</td>\n",
       "      <td>53.614498</td>\n",
       "      <td>10.003899</td>\n",
       "      <td>43.932011</td>\n",
       "      <td>12.790110</td>\n",
       "      <td>43.728970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.956089</td>\n",
       "      <td>54.234219</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>19.807215</td>\n",
       "      <td>4.939964</td>\n",
       "      <td>6.367033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.060045</td>\n",
       "      <td>7.886667</td>\n",
       "      <td>32.725471</td>\n",
       "      <td>36.889999</td>\n",
       "      <td>23.424749</td>\n",
       "      <td>...</td>\n",
       "      <td>53.456463</td>\n",
       "      <td>9.959157</td>\n",
       "      <td>44.870213</td>\n",
       "      <td>12.734954</td>\n",
       "      <td>43.591564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.950626</td>\n",
       "      <td>55.478374</td>\n",
       "      <td>27.690001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>19.800785</td>\n",
       "      <td>4.845691</td>\n",
       "      <td>6.409364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.157482</td>\n",
       "      <td>7.871111</td>\n",
       "      <td>32.595306</td>\n",
       "      <td>36.689999</td>\n",
       "      <td>23.559416</td>\n",
       "      <td>...</td>\n",
       "      <td>53.397202</td>\n",
       "      <td>9.867439</td>\n",
       "      <td>44.548744</td>\n",
       "      <td>12.741086</td>\n",
       "      <td>43.416687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.956089</td>\n",
       "      <td>54.313072</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Symbol              A       AAL      AAPL  ABBV  ABNB        ABT      ACGL  \\\n",
       "Date                                                                         \n",
       "2010-01-04  20.122227  4.496877  6.470741   NaN   NaN  18.952162  7.994444   \n",
       "2010-01-05  19.903643  5.005957  6.481929   NaN   NaN  18.799042  7.967778   \n",
       "2010-01-06  19.832930  4.798554  6.378825   NaN   NaN  18.903446  7.933333   \n",
       "2010-01-07  19.807215  4.939964  6.367033   NaN   NaN  19.060045  7.886667   \n",
       "2010-01-08  19.800785  4.845691  6.409364   NaN   NaN  19.157482  7.871111   \n",
       "\n",
       "Symbol            ACN       ADBE        ADI  ...        WTW         WY  \\\n",
       "Date                                         ...                         \n",
       "2010-01-04  32.212460  37.090000  23.694084  ...  52.883579   9.905468   \n",
       "2010-01-05  32.411549  37.700001  23.656675  ...  52.765053  10.115747   \n",
       "2010-01-06  32.756096  37.619999  23.611784  ...  53.614498  10.003899   \n",
       "2010-01-07  32.725471  36.889999  23.424749  ...  53.456463   9.959157   \n",
       "2010-01-08  32.595306  36.689999  23.559416  ...  53.397202   9.867439   \n",
       "\n",
       "Symbol           WYNN        XEL        XOM  XYL        YUM        ZBH  \\\n",
       "Date                                                                     \n",
       "2010-01-04  41.963718  12.918809  43.185623  NaN  19.158102  52.587051   \n",
       "2010-01-05  44.515926  12.765595  43.354244  NaN  19.092571  54.251759   \n",
       "2010-01-06  43.932011  12.790110  43.728970  NaN  18.956089  54.234219   \n",
       "2010-01-07  44.870213  12.734954  43.591564  NaN  18.950626  55.478374   \n",
       "2010-01-08  44.548744  12.741086  43.416687  NaN  18.956089  54.313072   \n",
       "\n",
       "Symbol           ZBRA  ZTS  \n",
       "Date                        \n",
       "2010-01-04  28.670000  NaN  \n",
       "2010-01-05  28.620001  NaN  \n",
       "2010-01-06  28.400000  NaN  \n",
       "2010-01-07  27.690001  NaN  \n",
       "2010-01-08  27.600000  NaN  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df = pd.read_csv('../../data/market_data/sp500/sp500_stocks.csv')\n",
    "df = stocks_df.pivot(\n",
    "    index='Date', columns='Symbol', values='Adj Close')\n",
    "\n",
    "df = df.reset_index()\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_ff_factors</th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1963-07-31</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1963-08-31</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>-0.0080</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1963-09-30</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1963-10-31</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>-0.0139</td>\n",
       "      <td>-0.0010</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>-0.0201</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1963-11-30</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_ff_factors  Mkt-RF     SMB     HML     RMW     CMA      RF\n",
       "0      1963-07-31 -0.0039 -0.0041 -0.0097  0.0068 -0.0118  0.0027\n",
       "1      1963-08-31  0.0507 -0.0080  0.0180  0.0036 -0.0035  0.0025\n",
       "2      1963-09-30 -0.0157 -0.0052  0.0013 -0.0071  0.0029  0.0027\n",
       "3      1963-10-31  0.0253 -0.0139 -0.0010  0.0280 -0.0201  0.0029\n",
       "4      1963-11-30 -0.0085 -0.0088  0.0175 -0.0051  0.0224  0.0027"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff5 = pd.DataFrame(gff.famaFrench5Factor(frequency='m'))\n",
    "ff5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fff = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
    "\n",
    "N_lags = 10\n",
    "\n",
    "for f in fff:\n",
    "  for i in range(1, N_lags):\n",
    "    ff5[f'{f}_{i}L'] = ff5[f].shift(-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = pd.DataFrame(df[tickers[0]]).resample('ME').last()\n",
    "mon_rets = mon.pct_change().dropna()\n",
    "\n",
    "factors = ff5.rename(columns={'date_ff_factors': 'Date'})\n",
    "factors_0 = pd.merge(mon_rets, factors, on='Date', how='left')\n",
    "factors_0 = factors_0.dropna()\n",
    "\n",
    "Y = (factors_0[tickers[0]] - factors_0['RF'])\n",
    "X = factors_0.drop(\n",
    "    columns=['RF', tickers[0]]).set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15features_stable = ['RMW_5L',\n",
    "                        'RMW_2L',\n",
    "                        'SMB_6L',\n",
    "                        'CMA_9L',\n",
    "                        'SMB_2L',\n",
    "                        'HML_5L',\n",
    "                        'Mkt-RF_7L',\n",
    "                        'CMA_4L',\n",
    "                        'CMA_6L',\n",
    "                        'RMW_6L',\n",
    "                        'CMA_8L',\n",
    "                        'Mkt-RF_2L',\n",
    "                        'CMA',\n",
    "                        'RMW',\n",
    "                        'Mkt-RF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Loss: 0.026036083698272705\n",
      "Epoch [2/7], Loss: 0.026094980537891388\n",
      "Epoch [3/7], Loss: 0.026118701323866844\n",
      "Epoch [4/7], Loss: 0.02615668624639511\n",
      "Epoch [5/7], Loss: 0.026203643530607224\n",
      "Epoch [6/7], Loss: 0.02626100741326809\n",
      "Epoch [7/7], Loss: 0.026347221806645393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/Desktop/Projects/DS/cc/Fama-French-models/.venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05573223904128033"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "class MultiLayerNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MultiLayerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 4)\n",
    "        self.layer2 = nn.Linear(4, 8)\n",
    "        self.layer3 = nn.Linear(8, 32)\n",
    "        self.layer4 = nn.Linear(32, 64)\n",
    "        self.layer5 = nn.Linear(64, 32)\n",
    "        self.layer6 = nn.Linear(32, 16)\n",
    "        self.output_layer = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.layer1(x))\n",
    "        x = torch.tanh(self.layer2(x))\n",
    "        x = torch.tanh(self.layer3(x))\n",
    "        x = torch.tanh(self.layer4(x))\n",
    "        x = torch.tanh(self.layer5(x))\n",
    "        x = torch.tanh(self.layer6(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = MultiLayerNN(input_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 7\n",
    "batch_size = 2\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        inputs = X_train_tensor[i:i+batch_size]\n",
    "        targets = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Note: This is a basic example. Depending on your dataset and problem, you might need to adjust parameters like learning rate, batch size, etc.\n",
    "\n",
    "r2_score(targets.detach().numpy(), outputs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
